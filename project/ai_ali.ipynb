{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhnguyenvv/NLP-A/blob/main/ai_ali.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjLr_-jz7r9W",
        "outputId": "52cb21d4-9872-4b90-c0cc-e4fba2d37c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.6/314.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,371 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,077 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,037 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,756 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [830 kB]\n",
            "Fetched 7,306 kB in 18s (397 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio -q\n",
        "!pip install openai -q\n",
        "!pip install gtts -q\n",
        "!pip install pydub -q\n",
        "!pip install config -q\n",
        "!pip install git+https://github.com/openai/whisper.git -q\n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install gdown -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTENxSh492It"
      },
      "outputs": [],
      "source": [
        "import gradio\n",
        "import config\n",
        "from gtts import gTTS\n",
        "import os\n",
        "import subprocess\n",
        "from pydub import AudioSegment\n",
        "import math\n",
        "import whisper\n",
        "from openai import OpenAI\n",
        "import requests, gdown\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load whisper model"
      ],
      "metadata": {
        "id": "NNtL67nSBNSq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAlxhz_lFejg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d2bd85-1214-453f-a0bb-f165aaaec2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:11<00:00, 130MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Checking if NVIDIA GPU is available\n",
        "torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "W_model = whisper.load_model(\"base\", device=DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eDC_5_k8TVr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F81WeS25R7fC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92f56167-bd4f-478a-9f8c-e2581d8cf686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v7SsfHr-slNIjVZ7tnliNJXYetVgwVya\n",
            "To: /content/Samples/SampleCall1.mp3\n",
            "100%|██████████| 2.86M/2.86M [00:00<00:00, 206MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1vtdKzRvIwINdWEmnKG-U-VhFkrzTLDRL\n",
            "To: /content/Samples/SampleCall2.mp3\n",
            "100%|██████████| 1.85M/1.85M [00:00<00:00, 148MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v7SsfHr-slNIjVZ7tnliNJXYetVgwVya\n",
            "To: /content/Samples/SampleCall3.mp3\n",
            "100%|██████████| 2.86M/2.86M [00:00<00:00, 201MB/s]\n"
          ]
        }
      ],
      "source": [
        "#File Project1_Data.json\n",
        "file_id = [\"1v7SsfHr-slNIjVZ7tnliNJXYetVgwVya\",\n",
        "           \"1vtdKzRvIwINdWEmnKG-U-VhFkrzTLDRL\",\n",
        "           \"1v7SsfHr-slNIjVZ7tnliNJXYetVgwVya\"\n",
        "]\n",
        "datafilename =[ \"./Samples/SampleCall1.mp3\",\n",
        "        \"./Samples/SampleCall2.mp3\",\n",
        "        \"./Samples/SampleCall3.mp3\"]\n",
        "import os\n",
        "os.makedirs('Samples')\n",
        "for i in range(len(file_id)):\n",
        "   with open(datafilename[i], 'wb') as f:\n",
        "     gdown.download(f\"https://drive.google.com/uc?id={file_id[i]}\", datafilename[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tran = W_model.transcribe(\"./Samples/SampleCall2.mp3\")\n"
      ],
      "metadata": {
        "id": "nst--XOuTWw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lLMjBhPzBTF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set your OpenAI API key\n",
        "client = OpenAI(api_key = \"sk-oGx8ZhLZ0xMahXqAF3tGcsTQhfO7WGIiRC0UlwtNYKJU9pxu\",\n",
        "                base_url=\"https://api.chatanywhere.tech/v1\")\n",
        "messages_system = {}\n",
        "messages_system['en']= {\"role\": \"system\",\n",
        "                        \"content\": \"You are a call center quality and assurance auditor. Your job is to review the call recording, and provide a very brief summary of the key information in the call including Operator’s Name, Call Category, Issue, and Solution. Also, you need to conduct sentiment analysis on the call and evaluate the customers satisfaction rate from 1 to 10 and provide a very short straight-to-the-point area of improvement to the operator.\"}\n",
        "messages_system['vi']= {\"role\": \"system\",\n",
        "                        \"content\": \"Bạn là kiểm toán viên đảm bảo chất lượng của trung tâm cuộc gọi. Công việc của bạn là xem lại bản ghi cuộc gọi và cung cấp bản tóm tắt rất ngắn gọn về thông tin chính trong cuộc gọi bao gồm: Tên người trực tổng đài, Loại cuộc gọi, Vấn đề, và Giải pháp. Ngoài ra, bạn cần tiến hành phân tích cảm xúc của khách hàng trong cuộc gọi và đánh giá mức độ hài lòng của khách hàng từ 1 đến 10, đồng thời cung cấp một phạm vi cải tiến rất ngắn gọn và đi thẳng vào vấn đề cho người trực tổng đài.\"}\n",
        "# Transcribe audio using OpenAI's Whisper\n",
        "def transcribe_audio(audio):\n",
        "    segment_length = 600000\n",
        "    # Open the audio file\n",
        "    audio_file = AudioSegment.from_file(audio)\n",
        "    # Get the duration of the audio file in milliseconds\n",
        "    duration_ms = len(audio_file)\n",
        "    # Calculate the number of segments needed\n",
        "    num_segments = math.ceil(duration_ms / segment_length)\n",
        "    # Create an empty string to hold the concatenated text\n",
        "    all_text = {'text': \"\",\n",
        "                'segments': \"\"}\n",
        "    # Split the audio file into segments\n",
        "    for i in range(num_segments):\n",
        "        start = i * segment_length\n",
        "        end = min((i + 1) * segment_length, duration_ms)\n",
        "        segment = audio_file[start:end]\n",
        "        segment.export(f\"segment_{i}.mp3\", format=\"mp3\")\n",
        "\n",
        "\n",
        "    for i in range(num_segments):\n",
        "        audio_file = open(f\"segment_{i}.mp3\", \"rb\")\n",
        "        transcript = W_model.transcribe(f\"segment_{i}.mp3\")\n",
        "        #transcript = client.audio.transcriptions.create(\n",
        "           # model=\"whisper-1\",\n",
        "           # file=audio_file)\n",
        "        all_text['text'] += transcript['text']\n",
        "        for s in transcript['segments']:\n",
        "          all_text['segments'] += str(datetime.timedelta(seconds = s['start']+i*600)) + \" - \" + str(\n",
        "              datetime.timedelta(seconds = s['end']+i*600)) + \": \" + s['text'] +\"\\n\"\n",
        "\n",
        "    return all_text\n",
        "\n",
        "# Analyze transcript using OpenAI's GPT-3\n",
        "def analyze_transcript(transcript, language= 'en'):\n",
        "    global messages_system\n",
        "    messages=[]\n",
        "    messages.append(messages_system[language])\n",
        "    messages.append({\"role\": \"user\", \"content\": transcript['text']})\n",
        "    response = client.chat.completions.create(\n",
        "          messages= messages,\n",
        "          model=\"gpt-3.5-turbo\",\n",
        "      )\n",
        "\n",
        "    systems_message = response.choices[0].message.content\n",
        "    messages.append({\"role\": \"assistant\", \"content\": systems_message})\n",
        "\n",
        "    chat_transcript = \"\"\n",
        "    for message in messages:\n",
        "        if message['role'] != 'system':\n",
        "            chat_transcript += message['role'] + \": \" + message['content'] + \"\\n\\n\"\n",
        "    result = \"Transcript: \" + transcript['segments'] + \"\\n\\n\"\n",
        "    '''for s in transcript['segments']:\n",
        "      result += str(datetime.timedelta(seconds = s['start'])) + \" - \" + str(\n",
        "          datetime.timedelta(seconds = s['end'])) + \": \" + s['text'] +\"\\n\"'''\n",
        "    return systems_message +\"\\n\\n\"+ result\n",
        "# Define the transcription and analysis function\n",
        "def transcribe_and_analyze(mic=None, file=None, language='en'):\n",
        "    if mic is not None:\n",
        "        audio = mic\n",
        "    elif file is not None:\n",
        "        audio = file\n",
        "    else:\n",
        "        return \"You must either provide a mic recording or a file\"\n",
        "    # Transcribe the audio to text\n",
        "    #transcript =  \"Thank you for calling Coats and Gowns, my name is Sam, how can I help you? Oh yes, I bought a coat from you guys but I need to return it because it was the wrong size and my size is not available. I haven't received any email from you and I wonder if my payment has been refunded. Seems like it does not apply on my account yet. I do apologize for the inconvenience but let me go ahead and check if there are some notes in the order details. May I ask for the original online order number? Okay, let me see. Please wait for a moment. Okay, hold on. Okay, I believe it's 017-1425-793. Thank you. Just to verify that's 017-1425-793, correct? Yes, that's right. I do apologize but the one that you provided is actually not accepting towards our database. Do you actually have a number that starts with 0007 or 7? Or can I ask for your first and last name so I can manually check it in our database? Yeah, I'm not sure about 000 something. Anyway, it's Adam Wilson. Alright, thank you. So Wilson is spelled as W for Whiskey, I for India, L for Lima, S for Sierra, O for Oscar and for November. Is that correct, Adam? Yes. Alright, thank you for that information. Okay, let me just quickly log into a portal and check any notes in your order. Do you still have the return tracking from the courier company when you return the item? Not sure. Is it the 74391? That's actually the return authorization from coats and gowns. When you return the item to the courier company for shipping, they should have provided you with the return tracking. Do you still have that? It's actually printed in the upper right part of the receipt. Okay, I probably have to dig it up. Okay, I imagine I have it somewhere but it might take some time to look for that. Oh, I see. Anyway, I tried to search for your name and nothing is coming up. Can I ask for the order under your name originally? Yeah, yeah, it's under my name. So it's not under Andy or something? It's Adam? Yeah, exactly. Thank you. Now, what's the phone number that you put in the order before? Okay, probably it's 411-345-0377. Thank you. So it's 411-345-0377, is that correct? Oh, it's 0377. Okay, and what's the email address that you gave when you filled out the order form? Okay, that should be adam.wilson.mailfence.com. Thank you. So again, it's adam.wilson.mailfence.com, is that correct? Yes, it is. Thank you. Adam, Adam underscore Wilson at mailfence.com. Okay, thank you. Now, I just want to make sure that I have the correct details. Please hold on for a moment while we check on the details here in my end, okay? Oh, sure, no problem. All right. Okay, thank you for patiently waiting, Adam. Now, I can actually see here that you have called to inform us that you'd like to return the item on the 15th of November, is that correct? Yes. Now, did you return the item to the courier company on the same day that you called? Probably close to it. I'm not really sure if it's on the same day though, but probably just close to that day. I understand. However, upon checking the date that you actually called in for the return, it's already beyond the timeframe that we ask for refunds. So, what we'll do is I'll go ahead and forward this information to our corporate office and I'll have them check and update you directly about the refund. So, please expect an email within two to four business days. Is that okay with you? Two to four business days? Yes. No worries. I will send it to them right now. Oh really? Okay. Alright, alright. At first I thought that it will probably be like three to five weeks to process. Oh, no, no, no, no. Don't worry, Adam. It's only two to four business days. So, you already checked your account and nothing has been credited yet on the card ending in 7-5-3, is that right? Nothing yet. Okay, I understand. And I'll go ahead and forward them to the... forward them the details that I have here. So, I'll send the email to adam.wilson.mailfence.com, correct? Yes, that's right. Alright, thank you so much for that information, Adam. I will be forwarding this over to our corporate office now and thank you again for calling Coats and Gowns. Is there anything else I can help you with today? Oh, no, that's all. Thank you. You're welcome and my pleasure. Have a nice day. Bye. Alright, thank you. Thank you.\"\n",
        "    transcript = transcribe_audio(audio)\n",
        "    # Analyze sentiment and summarize\n",
        "    analysis = analyze_transcript(transcript, language)\n",
        "    return analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "-aMUTzWsOuDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo by gradio Interface"
      ],
      "metadata": {
        "id": "Vpx0mTSfBJuC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mXwSF6rDsAG1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "outputId": "a527c2cb-8760-48ea-c07c-0740edd28a52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://c038472d5627edafc8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://c038472d5627edafc8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "\n",
        "io = gradio.Interface(fn=transcribe_and_analyze,\n",
        "                      inputs=[\n",
        "                          gradio.Audio(sources=\"microphone\", type=\"numpy\", label=\"Speak here...\"),\n",
        "                          gradio.Audio(sources=\"upload\", type = \"filepath\"),\n",
        "                          gradio.Radio([\"en\", \"vi\"], label=\"Language\")\n",
        "                      ],\n",
        "                      outputs=\"text\",\n",
        "                      title=\"AI Auditor for Call Center's Quality Assurance\",\n",
        "                      description=\"AI Alliance for Audio Analytics Team. Our project's objective is to conduct quality assurance on recorded calls, by transcribing the speech in the call to text using Whisper and then employing GPT-3 for sentiment analysis, summarisation, and feedback including areas for improvement. \",\n",
        "                      examples=[[None, \"./Samples/SampleCall1.mp3\"],\n",
        "                                [None, \"./Samples/SampleCall2.mp3\"],\n",
        "                                [None, \"./Samples/SampleCall3.mp3\"]],\n",
        "                      )\n",
        "\n",
        "io.launch(share=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
